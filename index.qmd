---
title: "Cyclistic Bike-Share Analysis"
subtitle: "Google Data Analytics Capstone"
author: "Roberto_Antuna"
date: "2026-02-02"
format:
  html:
    toc: true
    toc-location: left
    code-fold: true
    theme: cosmo
    echo: true
editor_options: 
  chunk_output_type: console
---

## Introduction

Cyclistic is a fictional company launched in Chicago in 2016. The company specializes in providing residents with bicycles for use within the city. Currently, they have more than **5,800 bicycles** and more than **650 docking stations**.

Cyclistic offers flexible plans for utilizing their equipment:

-   Single-ride pass\
-   Full-day pass\
-   Annual membership

The first two categories are considered ***Casual riders*** (Customers according to the records), while the third category consists of ***Cyclistic members*** (Subscribers according to the records).

In addition to conventional bicycles, Cyclistic provides three inclusive options:

::: {layout-ncol="3" style="text-align: center;"}
![Reclining Bikes](images/reclining_bike.png)

![Hand Tricycles](images/hand_tricycle.png)

![Cargo Bikes](images/cargo_bike.png)
:::

The marketing analyst team, led by Director Lily Moreno, has identified that 92% of users utilize conventional bicycles. Furthermore, 70% of users use the equipment for recreational purposes, while the remaining 30% use it as a means of transportation to work.

Given that annual memberships yield the highest profits, the marketing team aims to better understand users, their needs, and attraction channels (digital media) to **convert casual riders into Cyclistic members**.

![](images/cyclistic.png){fig-alt="Cyclistic logo" fig-align="center"}

## 1. Ask

### Business Task

The primary objective of this analysis is to identify key differences in how annual members and casual riders utilize Cyclistic's bike-share service. By extracting these insights from historical trip data, I aim to provide data-driven recommendations for a marketing strategy specifically designed to convert casual riders into long-term annual members, thereby driving sustainable growth for the company.

### Key Stakeholders

-   **Lily Moreno:** Director of Marketing and my manager. She is responsible for the development of campaigns and initiatives to promote the bike-share program.
-   **Cyclistic Marketing Analytics Team:** A team of data analysts who are responsible for collecting, analyzing, and reporting data that helps guide Cyclistic’s marketing strategy.
-   **Cyclistic Executive Team:** The notoriously detail-oriented executive team who will decide whether to approve the recommended marketing program.

### Primary Question

To guide the marketing strategy, this report focuses on answering:\
**How do annual members and casual riders use Cyclistic bikes differently?**

## 2. Prepare

### Data Sources

For this analysis, I will use Cyclistic’s historical trip data to identify trends. To ensure technical efficiency and follow project guidelines, the scope is limited to the following datasets:

**1.-** **Divvy_Trips_2019_Q1.csv**\
**2.-** **Divvy_Trips_2020_Q1.csv**

This data is public and has been made available by Motivate International Inc. under this [license](https://divvybikes.com/data-license-agreement).

### Data Credibility (ROCCC Analysis)

-   **Reliable:** The data is accurate and complete, representing a full quarter of activity for each year.
-   **Original:** The data comes directly from the City of Chicago’s bike-share program (Divvy).
-   **Comprehensive:** It includes essential variables such as ride duration, start/end times, and station names.
-   **Current:** While from 2019-2020, it provides the necessary historical context to answer the primary business question.
-   **Cited:** The data is officially documented and maintained by the service provider.

### Data Integrity & Privacy

-   **Privacy:** To protect user identity, personally identifiable information (PII) such as credit card numbers and home addresses has been excluded from the datasets.
-   **Limitations:** Demographic data (gender and age) is available for 2019 but was removed from the 2020 dataset; therefore, this analysis will focus primarily on usage patterns rather than demographics.

## 3. Process

In this phase, the data is processed to ensure it is clean, consistent, and ready for analysis. I am using **R** and the **tidyverse** ecosystem due to their efficiency in handling large datasets and ensuring reproducible results.

### 3.1 Setup and Data Import

First, I load the necessary libraries and import the datasets for the first quarter of 2019 and 2020. Following the project guidelines, the scope is focused on these specific periods to ensure technical efficiency.

```{r}
#| label: Packages
#| message: false
#Import libraries
library(tidyverse)
library(lubridate)
library(janitor)
```

```{r}
#| label: importing-data
# Import datasets
q1_2019 <- read_csv("data/Divvy_Trips_2019_Q1.csv", show_col_types = FALSE)
q1_2020 <- read_csv("data/Divvy_Trips_2020_Q1.csv", show_col_types = FALSE)
```

### 3.2 Data Inspection

Before any manipulation, it is essential to understand the structure and data types of the imported datasets. This step confirms the consistency of the data and identifies necessary cleaning tasks.

```{r}
#| label: inspection
# Inspect the structure of both datasets
glimpse(q1_2019)
glimpse(q1_2020)
```

### 3.3 Column Standardization

The inspection confirmed that the 2019 dataset uses a legacy naming convention (e.g., `trip_id`, `usertype`) compared to the 2020 version. To facilitate a clean merge, I am renaming the 2019 columns to align with the current standard.

```{r}
#| label: rename-columns
q1_2019 <- q1_2019 |>  
  rename(ride_id = trip_id,
        rideable_type = bikeid,
        started_at = start_time,
        ended_at = end_time,
        start_station_name = from_station_name,
        start_station_id = from_station_id,
        end_station_name = to_station_name,
        end_station_id = to_station_id,
        member_casual = usertype)
```

### 3.4 Data Consistency & Type Conversion

After renaming the columns, it is crucial to align the data types. In the 2019 dataset, `ride_id` and `rideable_type` are stored as numeric values, whereas the 2020 dataset stores them as characters. I will convert the 2019 columns to character format to ensure a seamless merge.

Additionally, I am consolidating the `member_casual` labels. The 2019 data uses "Subscriber" and "Customer," while 2020 uses "member" and "casual." I will standardize these to the current two-category format.

```{r}
#| label: type-conversion-and-recode

# Convert IDs to character for compatibility
q1_2019 <- q1_2019 |>  
  mutate(ride_id = as.character(ride_id),
        rideable_type = as.character(rideable_type)) 

# Consolidate user labels in both datasets
q1_2019 <- q1_2019 |> 
  mutate(member_casual = recode(member_casual,
                                "Subscriber" = "member",
                                "Customer" = "casual"))

q1_2020 <- q1_2020 |> 
  mutate(member_casual = recode(member_casual,
                                "Subscriber" = "member",
                                "Customer" = "casual"))
```

### 3.5 Merging Datasets

With identical column names and data types, I am stacking the datasets into a single data frame named `all_trips`. To optimize system memory, I will remove the original data frames from the environment once the merge is complete.

```{r}
#| label: merge-data
# Stack the data frames
all_trips <- bind_rows(q1_2019, q1_2020)

# Remove separate data frames to save RAM
rm(q1_2019, q1_2020)
```

#### 3.6 Adding Time Metrics

To answer how users utilize the service differently, I will extract the date, month, and day of the week from the `started_at` column. Additionally, I will calculate the `ride_length` in minutes.

```{r}
#| label: time-metrics
# Ensure date labels are in English for consistency
Sys.setlocale("LC_TIME", "English")
# Extract date components and calculate duration
all_trips <- all_trips |> 
  mutate(date = as.Date(started_at),
         month = format(as.Date(date), "%m"),
         day = format(as.Date(date), "%d"),
         year = format(as.Date(date), "%Y"),
         day_of_week = format(as.Date(date), "%A"),
         ride_length = as.numeric(difftime(ended_at, started_at, units = "mins")))

# Quick check of the new columns
head(all_trips |> select(started_at, ended_at, ride_length, day_of_week))
```

### 3.7 Data Cleaning and Validation

The final step in the process phase is to remove data that could skew the results. This includes trips with a duration of zero or less, and entries associated with administrative stations (such as "HQ QR") that do not represent actual customer trips.

```{r}
#| label: cleaning
# Filter out invalid durations and administrative station entries
all_trips_v2 <- all_trips |> 
  filter(start_station_name != "HQ QR" | is.na(start_station_name)) |> 
  filter(ride_length > 0)

# Verify the final dimensions of the clean dataset
dim(all_trips_v2)

# station_names validation
all_trips_v2 |> 
  group_by(start_station_id) |> 
  filter(n_distinct(start_station_name) > 1) |> 
  summarise(names = list(unique(start_station_name))) |>
  ungroup() |>
  unnest(cols = names)
```

### 3.8 Station Name Standardization

A preliminary group analysis revealed that the same physical docking station was appearing under multiple names due to administrative tags or minor naming updates (e.g., ID 208 recorded as both 'Ashland Ave' and 'Laflin St'). **Failing to consolidate these would lead to fragmented insights**, underreporting the popularity of key locations. I have programmatically unified these identities to ensure a single source of truth for location-based behavior.

```{r}
#| label: station-deep-clean
# 1. Remove temporary and special character tags
all_trips_v2 <- all_trips_v2 |> 
  mutate(across(c(start_station_name, end_station_name), 
                ~ str_remove_all(., " \\(Temp\\)| \\(\\*\\)")))

# 2. Consolidate specific ID-name mismatches based on geographic verification
all_trips_v2 <- all_trips_v2 |> 
  mutate(start_station_name = case_when(
    start_station_id == 19  ~ "Loomis St & Taylor St",
    start_station_id == 208 ~ "Ashland Ave & 21st St",
    start_station_id == 217 ~ "Racine Ave & Fulton St",
    start_station_id == 286 ~ "Franklin St & Quincy St",
    TRUE ~ start_station_name
  ),
  end_station_name = case_when(
    end_station_id == 19  ~ "Loomis St & Taylor St",
    end_station_id == 208 ~ "Ashland Ave & 21st St",
    end_station_id == 217 ~ "Racine Ave & Fulton St",
    end_station_id == 286 ~ "Franklin St & Quincy St",
    TRUE ~ end_station_name
  ))

# Final Verification: Checking if any station still has more than one name
all_trips_v2 |> 
  group_by(start_station_id) |> 
  summarise(unique_names = n_distinct(start_station_name)) |> 
  filter(unique_names > 1)
```

### 3.9 Final Column Selection

To ensure a consistent analysis between 2019 and 2020, I have opted to remove the `gender` and `birthyear` columns. These variables were not collected in the 2020 dataset, and including them would result in an incomplete demographic profile. Additionally, the `tripduration` column from 2019 was removed in favor of the newly calculated `ride_length` variable to ensure a uniform measurement unit (minutes) across all records.

```{r}
#| label: drop-columns
# Remove inconsistent or redundant columns
all_trips_v2 <- all_trips_v2 |> 
  select(-c(gender, birthyear, tripduration))
```

### 3.10 Data Health Check & Quality Assurance

As a final step before analysis, I conducted a quality check using the `skimr` library to ensure there are no missing values in critical columns and to examine the distribution of `ride_length`.

```{r}
#| label: qa-check
#| message: false
library(skimr)

# Summary of the clean dataset
skim(all_trips_v2)

# Verify there are no NA values in key analytical columns
all_trips_v2 |> 
  summarise(
    na_ride_id = sum(is.na(ride_id)),
    na_member_casual = sum(is.na(member_casual)),
    na_ride_length = sum(is.na(ride_length))
  )
```

**Analyst Note:** The `skim` output confirms a clean dataset with **788,189 observations**. While coordinates (`lat`/`lng`) show some missing values (46%), this does not impact the primary business question regarding usage patterns by membership type.
